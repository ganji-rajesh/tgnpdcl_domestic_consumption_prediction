{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57634088",
   "metadata": {},
   "source": "# Electricity Demand Forecasting \u2014 Classical Time Series Models (Darts)\n**Data**: Monthly electricity consumption (KWh) | Jan 2019 \u2013 Jan 2026  \n**Goal**: Forecast next 3 months using classical time series models tracked via MLflow  \n**Library**: [Darts](https://unit8co.github.io/darts/) by Unit8  \n**Model Progression**: Baseline \u2192 SES \u2192 Holt's Linear \u2192 Holt-Winters (4 variants) \u2192 ARIMA (auto) \u2192 SARIMA (auto + manual candidates)\n"
  },
  {
   "cell_type": "markdown",
   "id": "85160670",
   "metadata": {},
   "source": "## 1. Imports & Configuration"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17743496",
   "metadata": {},
   "outputs": [],
   "source": "import warnings\nimport pickle\nimport os\nimport tempfile\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as mticker\nimport seaborn as sns\n\n# Darts core\nfrom darts import TimeSeries\nfrom darts.models import ExponentialSmoothing, ARIMA, AutoARIMA\nfrom darts.utils.utils import ModelMode, SeasonalityMode\nfrom darts.metrics import mae, rmse, mape\n\n# Stats helpers (for EDA/checks \u2014 not for model building)\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nfrom statsmodels.tsa.stattools import adfuller\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nfrom statsmodels.stats.diagnostic import acorr_ljungbox\n\n# MLflow\nimport mlflow\n\nwarnings.filterwarnings(\"ignore\")\nplt.rcParams.update({\"figure.dpi\": 120, \"figure.figsize\": (12, 4)})\n\n# \u2500\u2500 Global constants \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nFORECAST_HORIZON  = 3    # months ahead to forecast\nSEASONAL_PERIOD   = 12   # monthly data \u2192 annual seasonality\nTRAIN_END_DATE    = \"2025-09-01\"\nMLFLOW_TRACKING_URI = \"mlruns\"\n\nmlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\nprint(\"MLflow tracking URI:\", mlflow.get_tracking_uri())\n"
  },
  {
   "cell_type": "markdown",
   "id": "34587705",
   "metadata": {},
   "source": "## 2. Data Loading & Preprocessing"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82954079",
   "metadata": {},
   "outputs": [],
   "source": "RAW_DATA = {\n    \"month_year\": [\n        \"2019-01-01\",\"2019-02-01\",\"2019-03-01\",\"2019-04-01\",\"2019-05-01\",\"2019-06-01\",\n        \"2019-07-01\",\"2019-08-01\",\"2019-09-01\",\"2019-10-01\",\"2019-11-01\",\"2019-12-01\",\n        \"2020-01-01\",\"2020-02-01\",\"2020-03-01\",\"2020-04-01\",\"2020-05-01\",\"2020-06-01\",\n        \"2020-07-01\",\"2020-08-01\",\"2020-09-01\",\"2020-10-01\",\"2020-11-01\",\"2020-12-01\",\n        \"2021-01-01\",\"2021-02-01\",\"2021-03-01\",\"2021-04-01\",\"2021-05-01\",\"2021-06-01\",\n        \"2021-07-01\",\"2021-08-01\",\"2021-09-01\",\"2021-10-01\",\"2021-11-01\",\"2021-12-01\",\n        \"2022-01-01\",\"2022-02-01\",\"2022-03-01\",\"2022-04-01\",\"2022-05-01\",\"2022-06-01\",\n        \"2022-07-01\",\"2022-08-01\",\"2022-09-01\",\"2022-10-01\",\"2022-11-01\",\"2022-12-01\",\n        \"2023-01-01\",\"2023-02-01\",\"2023-03-01\",\"2023-04-01\",\"2023-05-01\",\"2023-06-01\",\n        \"2023-07-01\",\"2023-08-01\",\"2023-09-01\",\"2023-10-01\",\"2023-11-01\",\"2023-12-01\",\n        \"2024-01-01\",\"2024-02-01\",\"2024-03-01\",\"2024-04-01\",\"2024-05-01\",\"2024-06-01\",\n        \"2024-07-01\",\"2024-08-01\",\"2024-09-01\",\"2024-10-01\",\"2024-11-01\",\"2024-12-01\",\n        \"2025-01-01\",\"2025-02-01\",\"2025-03-01\",\"2025-04-01\",\"2025-05-01\",\"2025-06-01\",\n        \"2025-07-01\",\"2025-08-01\",\"2025-09-01\",\"2025-10-01\",\"2025-11-01\",\"2025-12-01\",\n        \"2026-01-01\",\n    ],\n    \"total_units_kwh\": [\n        199722489.0,196282917.0,229630601.0,307610021.0,378333246.0,386806926.0,\n        318453165.0,303440777.0,299577754.0,302758063.0,287854703.0,249393096.0,\n        226911059.0,233987135.0,249055256.0,311844901.0,378972626.0,371104608.0,\n        362331096.0,376818006.5,349757651.6,342309639.0,317955772.0,269855118.0,\n        243155839.6,253523091.0,263214583.0,339192666.0,405477414.0,2158077.0,\n        368050250.0,384068332.0,361304647.0,350300159.0,326220132.17,284013708.0,\n        243976433.0,236413333.11,260031223.0,371437583.28,424833878.1,443537503.0,\n        376807680.32,322593689.64,351653428.59,332648965.59,294138231.0,249154006.57,\n        259018866.16,255718830.0,262851784.0,341098867.0,373179111.0,468056532.0,\n        414786578.0,340837857.0,380861584.0,348924442.0,346219332.0,295555199.0,\n        240950774.0,288656864.0,296623052.0,389765964.0,467155674.0,276370652.0,\n        429853045.0,385815658.0,417634123.0,388451915.0,402365044.0,301822337.0,\n        292729563.0,303704651.0,328929748.0,427534816.0,485839957.0,498140707.0,\n        442414161.0,432117294.0,416787169.0,414938105.0,390481404.0,290133269.0,\n        273816782.0,\n    ],\n}\n\ndf = pd.DataFrame(RAW_DATA)\ndf[\"month_year\"] = pd.to_datetime(df[\"month_year\"])\ndf = df.set_index(\"month_year\")\ndf.index.freq = \"MS\"\n\nprint(f\"Shape     : {df.shape}\")\nprint(f\"Date range: {df.index.min().date()} \u2192 {df.index.max().date()}\")\nprint(f\"Null count: {df.isnull().sum().values[0]}\")\ndf.head()\n"
  },
  {
   "cell_type": "markdown",
   "id": "23156038",
   "metadata": {},
   "source": "## 3. Outlier Fix \u2014 2021-06"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12110854",
   "metadata": {},
   "outputs": [],
   "source": "OUTLIER_DATE = \"2021-06-01\"\nprint(f\"Original 2021-06 value : {df.loc[OUTLIER_DATE, 'total_units_kwh']:,.0f} KWh  \u2190 data entry error\")\n\ndf.loc[OUTLIER_DATE, \"total_units_kwh\"] = np.nan\ndf[\"total_units_kwh\"] = df[\"total_units_kwh\"].interpolate(method=\"time\")\n\nprint(f\"Imputed  2021-06 value : {df.loc[OUTLIER_DATE, 'total_units_kwh']:,.0f} KWh  \u2190 time-interpolated\")\n\nfig, ax = plt.subplots()\nax.plot(df.index, df[\"total_units_kwh\"], linewidth=1.5, color=\"steelblue\")\nax.axvline(pd.Timestamp(OUTLIER_DATE), color=\"red\", linestyle=\"--\", label=\"Outlier fixed (2021-06)\")\nax.set_title(\"Monthly Electricity Consumption \u2014 Cleaned Series\")\nax.set_ylabel(\"KWh\")\nax.yaxis.set_major_formatter(mticker.FuncFormatter(lambda x, _: f\"{x/1e6:.0f}M\"))\nax.legend()\nplt.tight_layout()\nplt.savefig(\"01_cleaned_series.png\", bbox_inches=\"tight\")\nplt.show()\n"
  },
  {
   "cell_type": "markdown",
   "id": "18316118",
   "metadata": {},
   "source": "## 4. Exploratory Data Analysis"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16406681",
   "metadata": {},
   "outputs": [],
   "source": "fig, axes = plt.subplots(3, 1, figsize=(12, 11))\n\n# Full series\naxes[0].plot(df.index, df[\"total_units_kwh\"], color=\"steelblue\", linewidth=1.5)\naxes[0].set_title(\"Full Time Series (Cleaned)\")\naxes[0].set_ylabel(\"KWh\")\naxes[0].yaxis.set_major_formatter(mticker.FuncFormatter(lambda x, _: f\"{x/1e6:.0f}M\"))\n\n# Monthly seasonality boxplot\ndf_eda = df.copy()\nmonth_labels = [\"Jan\",\"Feb\",\"Mar\",\"Apr\",\"May\",\"Jun\",\"Jul\",\"Aug\",\"Sep\",\"Oct\",\"Nov\",\"Dec\"]\ndf_eda[\"month_name\"] = df_eda.index.month.map(lambda m: month_labels[m - 1])\nsns.boxplot(\n    data=df_eda, x=\"month_name\", y=\"total_units_kwh\",\n    order=month_labels, ax=axes[1], palette=\"coolwarm\"\n)\naxes[1].set_title(\"Monthly Seasonality Boxplot (per Calendar Month)\")\naxes[1].set_xlabel(\"\")\naxes[1].set_ylabel(\"KWh\")\naxes[1].yaxis.set_major_formatter(mticker.FuncFormatter(lambda x, _: f\"{x/1e6:.0f}M\"))\n\n# Year-on-year overlay\ndf_eda[\"year\"]  = df_eda.index.year\ndf_eda[\"month\"] = df_eda.index.month\npivot = df_eda[df_eda[\"year\"] <= 2025].pivot_table(\n    index=\"month\", columns=\"year\", values=\"total_units_kwh\"\n)\nfor yr in pivot.columns:\n    axes[2].plot(month_labels, pivot[yr], marker=\"o\", markersize=3, label=str(yr), linewidth=1.2)\naxes[2].set_title(\"Year-on-Year Monthly Overlay (2019\u20132025)\")\naxes[2].set_ylabel(\"KWh\")\naxes[2].yaxis.set_major_formatter(mticker.FuncFormatter(lambda x, _: f\"{x/1e6:.0f}M\"))\naxes[2].legend(ncol=4, fontsize=8)\n\nplt.tight_layout()\nplt.savefig(\"02_eda.png\", bbox_inches=\"tight\")\nplt.show()\n"
  },
  {
   "cell_type": "markdown",
   "id": "45872950",
   "metadata": {},
   "source": "## 5. Seasonal Decomposition"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78559411",
   "metadata": {},
   "outputs": [],
   "source": "decomp = seasonal_decompose(df[\"total_units_kwh\"], model=\"multiplicative\", period=SEASONAL_PERIOD)\n\nfig, axes = plt.subplots(4, 1, figsize=(12, 10), sharex=True)\nfor ax, (comp, title, color) in zip(axes, [\n    (decomp.observed, \"Observed\",  \"steelblue\"),\n    (decomp.trend,    \"Trend\",     \"darkorange\"),\n    (decomp.seasonal, \"Seasonal\",  \"green\"),\n    (decomp.resid,    \"Residual\",  \"red\"),\n]):\n    ax.plot(comp.index, comp, color=color, linewidth=1.2)\n    ax.set_ylabel(title, fontsize=9)\n    ax.grid(alpha=0.3)\n\naxes[0].yaxis.set_major_formatter(mticker.FuncFormatter(lambda x, _: f\"{x/1e6:.0f}M\"))\nplt.suptitle(\"Multiplicative Seasonal Decomposition (period=12)\", y=1.01, fontsize=12)\nplt.tight_layout()\nplt.savefig(\"03_decomposition.png\", bbox_inches=\"tight\")\nplt.show()\n"
  },
  {
   "cell_type": "markdown",
   "id": "20578931",
   "metadata": {},
   "source": "## 6. Stationarity Check (ADF Test)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70960676",
   "metadata": {},
   "outputs": [],
   "source": "def run_adf(series: pd.Series, label: str) -> None:\n    result = adfuller(series.dropna(), autolag=\"AIC\")\n    stationary = result[1] < 0.05\n    print(f\"[{label:<30}]  ADF={result[0]:>8.4f}  p={result[1]:.4f}  Stationary={stationary}\")\n\nrun_adf(df[\"total_units_kwh\"],                        \"Raw Series\")\nrun_adf(df[\"total_units_kwh\"].diff(1),                \"1st Difference (d=1)\")\nrun_adf(df[\"total_units_kwh\"].diff(12),               \"Seasonal Diff (D=1, lag=12)\")\nrun_adf(df[\"total_units_kwh\"].diff(1).diff(12),       \"1st + Seasonal Diff (d=1, D=1)\")\n"
  },
  {
   "cell_type": "markdown",
   "id": "26501393",
   "metadata": {},
   "source": "## 7. ACF & PACF Plots"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42415346",
   "metadata": {},
   "outputs": [],
   "source": "fig, axes = plt.subplots(2, 2, figsize=(14, 7))\nplot_acf( df[\"total_units_kwh\"],                          lags=30, ax=axes[0][0], title=\"ACF \u2014 Raw Series\")\nplot_pacf(df[\"total_units_kwh\"],                          lags=30, ax=axes[0][1], title=\"PACF \u2014 Raw Series\")\nplot_acf( df[\"total_units_kwh\"].diff(1).diff(12).dropna(),lags=30, ax=axes[1][0], title=\"ACF \u2014 After d=1 + D=1 Differencing\")\nplot_pacf(df[\"total_units_kwh\"].diff(1).diff(12).dropna(),lags=30, ax=axes[1][1], title=\"PACF \u2014 After d=1 + D=1 Differencing\")\nplt.tight_layout()\nplt.savefig(\"04_acf_pacf.png\", bbox_inches=\"tight\")\nplt.show()\n"
  },
  {
   "cell_type": "markdown",
   "id": "52246720",
   "metadata": {},
   "source": "## 8. Build Darts TimeSeries Objects\nDarts requires data in its `TimeSeries` format. We create the full series, train, and test splits here.\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85084008",
   "metadata": {},
   "outputs": [],
   "source": "# Full series as Darts TimeSeries\nseries_full = TimeSeries.from_series(df[\"total_units_kwh\"])\n\n# Train / Test split \u2014 hold out last 4 months (Oct 2025 \u2013 Jan 2026)\ntrain_ts, test_ts = series_full.split_before(pd.Timestamp(\"2025-10-01\"))\n\nprint(f\"Full series : {series_full.start_time().date()} \u2192 {series_full.end_time().date()}  ({len(series_full)} obs)\")\nprint(f\"Train series: {train_ts.start_time().date()} \u2192 {train_ts.end_time().date()}  ({len(train_ts)} obs)\")\nprint(f\"Test  series: {test_ts.start_time().date()} \u2192 {test_ts.end_time().date()}   ({len(test_ts)} obs)\")\n"
  },
  {
   "cell_type": "markdown",
   "id": "74355433",
   "metadata": {},
   "source": "## 9. Shared Utilities"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51485409",
   "metadata": {},
   "outputs": [],
   "source": "def compute_metrics(actual_ts: TimeSeries, forecast_ts: TimeSeries) -> dict:\n    \"\"\"Compute MAE, RMSE, MAPE between a Darts actual and forecast TimeSeries.\"\"\"\n    return {\n        \"MAE\" : round(float(mae(actual_ts,  forecast_ts)), 2),\n        \"RMSE\": round(float(rmse(actual_ts, forecast_ts)), 2),\n        \"MAPE\": round(float(mape(actual_ts, forecast_ts)), 4),\n    }\n\n\ndef plot_forecast(\n    train_ts: TimeSeries,\n    test_ts: TimeSeries,\n    forecast_ts: TimeSeries,\n    model_name: str,\n    save_path: str,\n    conf_low: TimeSeries = None,\n    conf_high: TimeSeries = None,\n) -> None:\n    \"\"\"Plot train history, test actuals, forecast, and optional 95% CI band.\"\"\"\n    fig, ax = plt.subplots(figsize=(13, 4))\n\n    train_pd  = train_ts.pd_series()\n    test_pd   = test_ts.pd_series()\n    fc_pd     = forecast_ts.pd_series()\n\n    ax.plot(train_pd.index, train_pd,  label=\"Train\",        color=\"steelblue\",  linewidth=1.2)\n    ax.plot(test_pd.index,  test_pd,   label=\"Test Actual\",  color=\"black\",      linewidth=1.5, linestyle=\"--\")\n    ax.plot(fc_pd.index,    fc_pd,     label=f\"{model_name} Forecast\",\n            color=\"tomato\", linewidth=1.5, marker=\"o\", markersize=5)\n\n    if conf_low is not None and conf_high is not None:\n        ax.fill_between(\n            fc_pd.index,\n            conf_low.pd_series().values,\n            conf_high.pd_series().values,\n            alpha=0.2, color=\"tomato\", label=\"95% CI\",\n        )\n\n    ax.set_title(f\"{model_name} \u2014 Forecast vs Actual\")\n    ax.set_ylabel(\"KWh\")\n    ax.yaxis.set_major_formatter(mticker.FuncFormatter(lambda x, _: f\"{x/1e6:.0f}M\"))\n    ax.legend(fontsize=8)\n    ax.grid(alpha=0.3)\n    plt.tight_layout()\n    plt.savefig(save_path, bbox_inches=\"tight\")\n    plt.show()\n\n\ndef plot_residuals(residuals: pd.Series, model_name: str, save_path: str) -> None:\n    \"\"\"Residual time plot + ACF of residuals.\"\"\"\n    fig, axes = plt.subplots(1, 2, figsize=(13, 4))\n    axes[0].plot(residuals.index, residuals, color=\"purple\", linewidth=1)\n    axes[0].axhline(0, linestyle=\"--\", color=\"black\", linewidth=0.8)\n    axes[0].set_title(f\"{model_name} \u2014 Residuals\")\n    axes[0].grid(alpha=0.3)\n    plot_acf(residuals.dropna(), lags=20, ax=axes[1], title=f\"{model_name} \u2014 Residual ACF\")\n    plt.tight_layout()\n    plt.savefig(save_path, bbox_inches=\"tight\")\n    plt.show()\n\n\ndef ljung_box_test(residuals: pd.Series, lags: int = 10) -> dict:\n    \"\"\"Ljung-Box white-noise test on residuals.\"\"\"\n    lb = acorr_ljungbox(residuals.dropna(), lags=[lags], return_df=True)\n    return {\n        \"lb_stat\":   round(float(lb[\"lb_stat\"].values[0]),   4),\n        \"lb_pvalue\": round(float(lb[\"lb_pvalue\"].values[0]), 4),\n    }\n\n\ndef save_model_artifact(model, filename: str) -> str:\n    \"\"\"Pickle a Darts model and return the file path.\"\"\"\n    path = os.path.join(tempfile.gettempdir(), filename)\n    with open(path, \"wb\") as f:\n        pickle.dump(model, f)\n    return path\n\n\ndef log_run(\n    experiment_name: str,\n    run_name: str,\n    model_family: str,\n    model_variant: str,\n    params: dict,\n    metrics: dict,\n    lb: dict,\n    forecast_png: str,\n    residual_png: str,\n    model_obj,\n    extra_metrics: dict = None,\n) -> None:\n    \"\"\"Consolidated MLflow logging helper used by every model stage.\"\"\"\n    mlflow.set_experiment(experiment_name)\n    with mlflow.start_run(run_name=run_name):\n        mlflow.set_tag(\"model_family\",  model_family)\n        mlflow.set_tag(\"model_variant\", model_variant)\n        mlflow.set_tag(\"outlier_fixed\", \"True\")\n        mlflow.log_params(params)\n        mlflow.log_metrics(metrics)\n        mlflow.log_metrics(lb)\n        if extra_metrics:\n            mlflow.log_metrics(extra_metrics)\n        mlflow.log_artifact(forecast_png)\n        mlflow.log_artifact(residual_png)\n        model_path = save_model_artifact(model_obj, f\"{run_name}.pkl\")\n        mlflow.log_artifact(model_path, artifact_path=\"model\")\n    print(f\"[{run_name}] {metrics} | Ljung-Box p={lb['lb_pvalue']}\")\n\n\n# \u2500\u2500 Create MLflow experiments \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nEXP_SMOOTHING = \"exponential_smoothing\"\nEXP_ARIMA     = \"arima_sarima\"\n\nfor exp in [EXP_SMOOTHING, EXP_ARIMA]:\n    if not mlflow.get_experiment_by_name(exp):\n        mlflow.create_experiment(exp)\n        print(f\"Created experiment: {exp}\")\n    else:\n        print(f\"Experiment exists : {exp}\")\n"
  },
  {
   "cell_type": "markdown",
   "id": "22811585",
   "metadata": {},
   "source": "## 10. Stage 1 \u2014 Baseline Models\nBenchmarks that every subsequent model must beat.\n- **Mean Forecast**: predicts training mean for all test periods\n- **Drift Forecast**: extrapolates the line between first and last training point\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84758880",
   "metadata": {},
   "outputs": [],
   "source": "train_vals = train_ts.pd_series()\n\n# \u2500\u2500 Mean Baseline \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nmean_vals   = np.full(len(test_ts), train_vals.mean())\nfc_mean_ts  = TimeSeries.from_times_and_values(test_ts.time_index, mean_vals)\nmetrics_mean = compute_metrics(test_ts, fc_mean_ts)\n\nmlflow.set_experiment(EXP_SMOOTHING)\nwith mlflow.start_run(run_name=\"baseline_mean\"):\n    mlflow.set_tag(\"model_family\", \"baseline\")\n    mlflow.set_tag(\"model_variant\", \"mean\")\n    mlflow.set_tag(\"outlier_fixed\", \"True\")\n    mlflow.log_params({\"model_type\": \"mean_forecast\", \"forecast_horizon\": FORECAST_HORIZON})\n    mlflow.log_metrics(metrics_mean)\n    plot_forecast(train_ts, test_ts, fc_mean_ts, \"Mean Baseline\", \"05a_baseline_mean.png\")\n    mlflow.log_artifact(\"05a_baseline_mean.png\")\nprint(\"Mean Baseline \u2192\", metrics_mean)\n\n# \u2500\u2500 Drift Baseline \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nn = len(train_vals)\ndrift_slope = (train_vals.iloc[-1] - train_vals.iloc[0]) / (n - 1)\ndrift_vals  = np.array([train_vals.iloc[-1] + drift_slope * h for h in range(1, len(test_ts) + 1)])\nfc_drift_ts = TimeSeries.from_times_and_values(test_ts.time_index, drift_vals)\nmetrics_drift = compute_metrics(test_ts, fc_drift_ts)\n\nwith mlflow.start_run(run_name=\"baseline_drift\"):\n    mlflow.set_tag(\"model_family\", \"baseline\")\n    mlflow.set_tag(\"model_variant\", \"drift\")\n    mlflow.set_tag(\"outlier_fixed\", \"True\")\n    mlflow.log_params({\"model_type\": \"drift_forecast\", \"forecast_horizon\": FORECAST_HORIZON})\n    mlflow.log_metrics(metrics_drift)\n    plot_forecast(train_ts, test_ts, fc_drift_ts, \"Drift Baseline\", \"05b_baseline_drift.png\")\n    mlflow.log_artifact(\"05b_baseline_drift.png\")\nprint(\"Drift Baseline \u2192\", metrics_drift)\n"
  },
  {
   "cell_type": "markdown",
   "id": "22811198",
   "metadata": {},
   "source": "## 11. Stage 2 \u2014 Simple Exponential Smoothing (SES)\nIn Darts: `ExponentialSmoothing(trend=ModelMode.NONE, seasonal=SeasonalityMode.NONE)`.  \nModels level only \u2014 expected to underfit given trend + seasonality in data.\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41351898",
   "metadata": {},
   "outputs": [],
   "source": "model_ses = ExponentialSmoothing(\n    trend=ModelMode.NONE,\n    seasonal=SeasonalityMode.NONE,\n    seasonal_periods=SEASONAL_PERIOD,\n)\nmodel_ses.fit(train_ts)\nfc_ses = model_ses.predict(len(test_ts))\nmetrics_ses = compute_metrics(test_ts, fc_ses)\n\n# Residuals from fitted values\nfitted_vals_ses = model_ses.model.fittedvalues  # underlying statsmodels object\nresiduals_ses   = pd.Series(\n    train_ts.pd_series().values - fitted_vals_ses.values,\n    index=train_ts.time_index,\n)\nlb_ses = ljung_box_test(residuals_ses)\n\nplot_forecast(train_ts, test_ts, fc_ses, \"SES\", \"06_ses_forecast.png\")\nplot_residuals(residuals_ses, \"SES\", \"06_ses_residuals.png\")\n\nalpha_ses = round(model_ses.model.params[\"smoothing_level\"], 4)\nlog_run(\n    EXP_SMOOTHING, \"SES\", \"exponential_smoothing\", \"SES\",\n    params={\"model_type\": \"SES\", \"alpha\": alpha_ses, \"forecast_horizon\": FORECAST_HORIZON},\n    metrics=metrics_ses, lb=lb_ses,\n    forecast_png=\"06_ses_forecast.png\", residual_png=\"06_ses_residuals.png\",\n    model_obj=model_ses,\n)\n"
  },
  {
   "cell_type": "markdown",
   "id": "35036437",
   "metadata": {},
   "source": "## 12. Stage 3 \u2014 Holt's Linear Exponential Smoothing (Double ES)\nIn Darts: `ExponentialSmoothing(trend=ModelMode.ADDITIVE, seasonal=SeasonalityMode.NONE)`.  \nAdds trend component (\u03b1 + \u03b2). Two variants: standard and damped.\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45217140",
   "metadata": {},
   "outputs": [],
   "source": "holt_variants = [\n    {\"damped\": False, \"run_name\": \"Holts_Linear\",        \"label\": \"Holt Linear\"},\n    {\"damped\": True,  \"run_name\": \"Holts_Linear_Damped\", \"label\": \"Holt Linear Damped\"},\n]\n\nfor v in holt_variants:\n    model_holt = ExponentialSmoothing(\n        trend=ModelMode.ADDITIVE,\n        damped=v[\"damped\"],\n        seasonal=SeasonalityMode.NONE,\n        seasonal_periods=SEASONAL_PERIOD,\n    )\n    model_holt.fit(train_ts)\n    fc_holt = model_holt.predict(len(test_ts))\n    metrics_holt = compute_metrics(test_ts, fc_holt)\n\n    fitted_holt  = model_holt.model.fittedvalues\n    residuals_holt = pd.Series(\n        train_ts.pd_series().values - fitted_holt.values,\n        index=train_ts.time_index,\n    )\n    lb_holt = ljung_box_test(residuals_holt)\n\n    alpha = round(model_holt.model.params[\"smoothing_level\"], 4)\n    beta  = round(model_holt.model.params[\"smoothing_trend\"], 4)\n    phi   = round(model_holt.model.params.get(\"damping_trend\", 1.0), 4)\n\n    fc_png  = f\"07_{v['run_name']}_forecast.png\"\n    res_png = f\"07_{v['run_name']}_residuals.png\"\n    plot_forecast(train_ts, test_ts, fc_holt, v[\"label\"], fc_png)\n    plot_residuals(residuals_holt, v[\"label\"], res_png)\n\n    log_run(\n        EXP_SMOOTHING, v[\"run_name\"], \"exponential_smoothing\", v[\"run_name\"],\n        params={\n            \"model_type\": \"Holts_ExponentialSmoothing\",\n            \"trend\": \"additive\", \"damped\": v[\"damped\"],\n            \"alpha\": alpha, \"beta\": beta, \"phi\": phi,\n            \"forecast_horizon\": FORECAST_HORIZON,\n        },\n        metrics=metrics_holt, lb=lb_holt,\n        forecast_png=fc_png, residual_png=res_png,\n        model_obj=model_holt,\n        extra_metrics={\"AIC\": round(model_holt.model.aic, 4)},\n    )\n"
  },
  {
   "cell_type": "markdown",
   "id": "43582829",
   "metadata": {},
   "source": "## 13. Stage 4 \u2014 Holt-Winters Exponential Smoothing\nIn Darts: `ExponentialSmoothing` with both `trend` and `seasonal` set.  \nFour variants: additive/multiplicative seasonal \u00d7 standard/damped trend.\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22307672",
   "metadata": {},
   "outputs": [],
   "source": "hw_variants = [\n    {\"seasonal\": SeasonalityMode.ADDITIVE,       \"damped\": False,\n     \"run_name\": \"HW_Additive\",             \"label\": \"HW Additive\"},\n    {\"seasonal\": SeasonalityMode.ADDITIVE,       \"damped\": True,\n     \"run_name\": \"HW_Additive_Damped\",      \"label\": \"HW Additive Damped\"},\n    {\"seasonal\": SeasonalityMode.MULTIPLICATIVE, \"damped\": False,\n     \"run_name\": \"HW_Multiplicative\",       \"label\": \"HW Multiplicative\"},\n    {\"seasonal\": SeasonalityMode.MULTIPLICATIVE, \"damped\": True,\n     \"run_name\": \"HW_Multiplicative_Damped\",\"label\": \"HW Multiplicative Damped\"},\n]\n\nfor v in hw_variants:\n    model_hw = ExponentialSmoothing(\n        trend=ModelMode.ADDITIVE,\n        damped=v[\"damped\"],\n        seasonal=v[\"seasonal\"],\n        seasonal_periods=SEASONAL_PERIOD,\n    )\n    model_hw.fit(train_ts)\n    fc_hw = model_hw.predict(len(test_ts))\n    metrics_hw = compute_metrics(test_ts, fc_hw)\n\n    fitted_hw    = model_hw.model.fittedvalues\n    residuals_hw = pd.Series(\n        train_ts.pd_series().values - fitted_hw.values,\n        index=train_ts.time_index,\n    )\n    lb_hw = ljung_box_test(residuals_hw)\n\n    alpha = round(model_hw.model.params[\"smoothing_level\"],    4)\n    beta  = round(model_hw.model.params[\"smoothing_trend\"],    4)\n    gamma = round(model_hw.model.params[\"smoothing_seasonal\"], 4)\n    phi   = round(model_hw.model.params.get(\"damping_trend\", 1.0), 4)\n\n    fc_png  = f\"08_{v['run_name']}_forecast.png\"\n    res_png = f\"08_{v['run_name']}_residuals.png\"\n    plot_forecast(train_ts, test_ts, fc_hw, v[\"label\"], fc_png)\n    plot_residuals(residuals_hw, v[\"label\"], res_png)\n\n    log_run(\n        EXP_SMOOTHING, v[\"run_name\"], \"holt_winters\", v[\"run_name\"],\n        params={\n            \"model_type\": \"HoltWinters\",\n            \"trend\": \"additive\",\n            \"seasonal\": str(v[\"seasonal\"]).split(\".\")[-1].lower(),\n            \"seasonal_periods\": SEASONAL_PERIOD,\n            \"damped\": v[\"damped\"],\n            \"alpha\": alpha, \"beta\": beta, \"gamma\": gamma, \"phi\": phi,\n            \"forecast_horizon\": FORECAST_HORIZON,\n        },\n        metrics=metrics_hw, lb=lb_hw,\n        forecast_png=fc_png, residual_png=res_png,\n        model_obj=model_hw,\n        extra_metrics={\n            \"AIC\": round(model_hw.model.aic, 4),\n            \"BIC\": round(model_hw.model.bic, 4),\n        },\n    )\n"
  },
  {
   "cell_type": "markdown",
   "id": "85886765",
   "metadata": {},
   "source": "## 14. Stage 5 \u2014 ARIMA (Auto Order Selection)\nDarts `AutoARIMA` wraps `statsforecast.models.AutoARIMA` for automatic non-seasonal order selection.  \nActs as a stepping stone before adding the seasonal component.\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34701909",
   "metadata": {},
   "outputs": [],
   "source": "mlflow.set_experiment(EXP_ARIMA)\n\nprint(\"Fitting AutoARIMA (non-seasonal)...\")\nmodel_arima = AutoARIMA(season_length=1)   # season_length=1 \u2192 non-seasonal search\nmodel_arima.fit(train_ts)\nfc_arima = model_arima.predict(len(test_ts))\nmetrics_arima = compute_metrics(test_ts, fc_arima)\n\n# Extract fitted model internals via the underlying statsforecast model\narima_summary = model_arima.model  # statsforecast AutoARIMA result\n\nplot_forecast(train_ts, test_ts, fc_arima, \"AutoARIMA (non-seasonal)\", \"09_arima_forecast.png\")\n\n# Residuals: actual \u2212 fitted (use in-sample predict as proxy for fitted values)\nfc_insample  = model_arima.predict(len(train_ts), series=train_ts)\n# For residuals use statsmodels ARIMA wrapper via Darts ARIMA class with best order\nresiduals_arima = train_ts.pd_series() - fc_insample.pd_series().reindex(train_ts.time_index)\nresiduals_arima = residuals_arima.dropna()\nlb_arima = ljung_box_test(residuals_arima)\n\nplot_residuals(residuals_arima, \"AutoARIMA\", \"09_arima_residuals.png\")\n\nwith mlflow.start_run(run_name=\"ARIMA_auto\"):\n    mlflow.set_tag(\"model_family\",  \"arima\")\n    mlflow.set_tag(\"model_variant\", \"AutoARIMA_non_seasonal\")\n    mlflow.set_tag(\"outlier_fixed\", \"True\")\n    mlflow.log_params({\n        \"model_type\": \"AutoARIMA\", \"seasonal\": False,\n        \"season_length\": 1, \"forecast_horizon\": FORECAST_HORIZON,\n    })\n    mlflow.log_metrics(metrics_arima)\n    mlflow.log_metrics(lb_arima)\n    mlflow.log_artifact(\"09_arima_forecast.png\")\n    mlflow.log_artifact(\"09_arima_residuals.png\")\n    model_path = save_model_artifact(model_arima, \"arima_auto.pkl\")\n    mlflow.log_artifact(model_path, artifact_path=\"model\")\n\nprint(f\"AutoARIMA \u2192 {metrics_arima} | Ljung-Box p={lb_arima['lb_pvalue']}\")\n"
  },
  {
   "cell_type": "markdown",
   "id": "20794964",
   "metadata": {},
   "source": "## 15. Stage 6a \u2014 SARIMA (AutoARIMA with m=12)\nDarts `AutoARIMA(season_length=12)` searches optimal (p,d,q)(P,D,Q)[12] automatically.\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34701909",
   "metadata": {},
   "outputs": [],
   "source": "mlflow.set_experiment(EXP_ARIMA)\n\nprint(\"Fitting AutoARIMA (seasonal, m=12)... may take ~60 seconds.\")\nmodel_sarima_auto = AutoARIMA(season_length=SEASONAL_PERIOD)\nmodel_sarima_auto.fit(train_ts)\nfc_sarima_auto = model_sarima_auto.predict(len(test_ts))\nmetrics_sarima_auto = compute_metrics(test_ts, fc_sarima_auto)\n\nplot_forecast(train_ts, test_ts, fc_sarima_auto,\n              \"AutoARIMA SARIMA (m=12)\", \"10_sarima_auto_forecast.png\")\n\nfc_insample_s    = model_sarima_auto.predict(len(train_ts), series=train_ts)\nresiduals_sarima = (train_ts.pd_series()\n                    - fc_insample_s.pd_series().reindex(train_ts.time_index)).dropna()\nlb_sarima_auto   = ljung_box_test(residuals_sarima)\n\nplot_residuals(residuals_sarima, \"SARIMA Auto\", \"10_sarima_auto_residuals.png\")\n\nwith mlflow.start_run(run_name=\"SARIMA_auto\"):\n    mlflow.set_tag(\"model_family\",  \"sarima\")\n    mlflow.set_tag(\"model_variant\", \"AutoARIMA_seasonal_m12\")\n    mlflow.set_tag(\"outlier_fixed\", \"True\")\n    mlflow.log_params({\n        \"model_type\": \"AutoARIMA_seasonal\",\n        \"season_length\": SEASONAL_PERIOD,\n        \"forecast_horizon\": FORECAST_HORIZON,\n    })\n    mlflow.log_metrics(metrics_sarima_auto)\n    mlflow.log_metrics(lb_sarima_auto)\n    mlflow.log_artifact(\"10_sarima_auto_forecast.png\")\n    mlflow.log_artifact(\"10_sarima_auto_residuals.png\")\n    model_path = save_model_artifact(model_sarima_auto, \"sarima_auto.pkl\")\n    mlflow.log_artifact(model_path, artifact_path=\"model\")\n\nprint(f\"SARIMA Auto \u2192 {metrics_sarima_auto} | Ljung-Box p={lb_sarima_auto['lb_pvalue']}\")\n"
  },
  {
   "cell_type": "markdown",
   "id": "47017800",
   "metadata": {},
   "source": "## 16. Stage 6b \u2014 SARIMA Manual Candidates\nUsing Darts `ARIMA` class with explicit `(p,d,q)` and `seasonal_order=(P,D,Q,m)`.  \nFour candidates backed by ACF/PACF analysis (strong lag-1 and lag-12 autocorrelation).\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86999000",
   "metadata": {},
   "outputs": [],
   "source": "from statsmodels.tsa.statespace.sarimax import SARIMAX as SM_SARIMAX\n\nmlflow.set_experiment(EXP_ARIMA)\n\nsarima_candidates = [\n    {\"p\":1,\"d\":1,\"q\":1,\"P\":1,\"D\":1,\"Q\":1, \"run_name\":\"SARIMA_1_1_1_1_1_1_12\"},\n    {\"p\":1,\"d\":0,\"q\":1,\"P\":1,\"D\":1,\"Q\":1, \"run_name\":\"SARIMA_1_0_1_1_1_1_12\"},\n    {\"p\":2,\"d\":1,\"q\":1,\"P\":1,\"D\":1,\"Q\":1, \"run_name\":\"SARIMA_2_1_1_1_1_1_12\"},\n    {\"p\":1,\"d\":1,\"q\":2,\"P\":1,\"D\":1,\"Q\":1, \"run_name\":\"SARIMA_1_1_2_1_1_1_12\"},\n]\n\nfor c in sarima_candidates:\n    label = f\"SARIMA({c['p']},{c['d']},{c['q']})({c['P']},{c['D']},{c['Q']})[12]\"\n    try:\n        # Darts ARIMA with seasonal_order\n        model_s = ARIMA(\n            p=c[\"p\"], d=c[\"d\"], q=c[\"q\"],\n            seasonal_order=(c[\"P\"], c[\"D\"], c[\"Q\"], SEASONAL_PERIOD),\n        )\n        model_s.fit(train_ts)\n        fc_s = model_s.predict(len(test_ts))\n        metrics_s = compute_metrics(test_ts, fc_s)\n\n        # Confidence intervals via underlying statsmodels object\n        sm_result     = model_s.model  # fitted statsmodels SARIMAXResults\n        fc_sm         = sm_result.get_forecast(steps=len(test_ts))\n        conf_int      = fc_sm.conf_int()\n        conf_low_ts   = TimeSeries.from_times_and_values(\n            test_ts.time_index, conf_int.iloc[:, 0].values\n        )\n        conf_high_ts  = TimeSeries.from_times_and_values(\n            test_ts.time_index, conf_int.iloc[:, 1].values\n        )\n\n        residuals_s = pd.Series(sm_result.resid, index=train_ts.time_index)\n        lb_s        = ljung_box_test(residuals_s)\n\n        fc_png  = f\"11_{c['run_name']}_forecast.png\"\n        res_png = f\"11_{c['run_name']}_residuals.png\"\n        plot_forecast(train_ts, test_ts, fc_s, label, fc_png, conf_low_ts, conf_high_ts)\n        plot_residuals(residuals_s, label, res_png)\n\n        log_run(\n            EXP_ARIMA, c[\"run_name\"], \"sarima\", label,\n            params={\n                \"model_type\": \"SARIMA_manual\",\n                \"p\": c[\"p\"], \"d\": c[\"d\"], \"q\": c[\"q\"],\n                \"P\": c[\"P\"], \"D\": c[\"D\"], \"Q\": c[\"Q\"], \"m\": SEASONAL_PERIOD,\n                \"forecast_horizon\": FORECAST_HORIZON,\n            },\n            metrics=metrics_s, lb=lb_s,\n            forecast_png=fc_png, residual_png=res_png,\n            model_obj=model_s,\n            extra_metrics={\n                \"AIC\": round(sm_result.aic, 4),\n                \"BIC\": round(sm_result.bic, 4),\n            },\n        )\n\n    except Exception as e:\n        print(f\"Failed {c['run_name']}: {e}\")\n"
  },
  {
   "cell_type": "markdown",
   "id": "46420088",
   "metadata": {},
   "source": "## 17. Model Comparison \u2014 MLflow Results Summary"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15816492",
   "metadata": {},
   "outputs": [],
   "source": "def fetch_runs(experiment_name: str) -> pd.DataFrame:\n    exp = mlflow.get_experiment_by_name(experiment_name)\n    return mlflow.search_runs([exp.experiment_id]) if exp else pd.DataFrame()\n\ncols = [\"tags.mlflow.runName\",\"metrics.MAPE\",\"metrics.RMSE\",\"metrics.MAE\",\n        \"metrics.AIC\",\"metrics.BIC\",\"metrics.lb_pvalue\",\"tags.model_family\"]\n\nall_runs = pd.concat([fetch_runs(EXP_SMOOTHING), fetch_runs(EXP_ARIMA)], ignore_index=True)\navail    = [c for c in cols if c in all_runs.columns]\n\nsummary = (\n    all_runs[avail]\n    .rename(columns={\n        \"tags.mlflow.runName\":  \"Model\",\n        \"metrics.MAPE\":        \"MAPE(%)\",\n        \"metrics.RMSE\":        \"RMSE\",\n        \"metrics.MAE\":         \"MAE\",\n        \"metrics.AIC\":         \"AIC\",\n        \"metrics.BIC\":         \"BIC\",\n        \"metrics.lb_pvalue\":   \"LjungBox_p\",\n        \"tags.model_family\":   \"Family\",\n    })\n    .sort_values(\"MAPE(%)\")\n    .reset_index(drop=True)\n)\n\npd.set_option(\"display.float_format\", lambda x: f\"{x:,.4f}\")\nprint(\"\\n===== MODEL COMPARISON (sorted by MAPE) =====\\n\")\nprint(summary.to_string(index=False))\nsummary.to_csv(\"12_model_comparison.csv\", index=False)\nprint(\"\\nSaved: 12_model_comparison.csv\")\n"
  },
  {
   "cell_type": "markdown",
   "id": "55409843",
   "metadata": {},
   "source": "## 18. Final Forecast \u2014 Best Model Retrained on Full Data\nRetrain the best-performing model on the **full dataset** (all 85 months including Jan 2026)  \nand forecast Feb\u2013Apr 2026 (next 3 months).\n\n> Update `BEST_MODEL_TYPE` below after reviewing the comparison table in Section 17.\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73566265",
   "metadata": {},
   "outputs": [],
   "source": "# \u2500\u2500 Select best model type after reviewing Section 17 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# Options: \"hw_multiplicative_damped\"  |  \"sarima_manual\"  |  \"sarima_auto\"\nBEST_MODEL_TYPE = \"hw_multiplicative_damped\"   # update if SARIMA wins\n\nfuture_index = pd.date_range(start=\"2026-02-01\", periods=FORECAST_HORIZON, freq=\"MS\")\n\nif BEST_MODEL_TYPE == \"hw_multiplicative_damped\":\n    best_model = ExponentialSmoothing(\n        trend=ModelMode.ADDITIVE,\n        damped=True,\n        seasonal=SeasonalityMode.MULTIPLICATIVE,\n        seasonal_periods=SEASONAL_PERIOD,\n    )\n    best_model.fit(series_full)\n    final_forecast_ts = best_model.predict(FORECAST_HORIZON)\n    model_label = \"HW Multiplicative Damped (Full Data)\"\n\nelif BEST_MODEL_TYPE == \"sarima_auto\":\n    best_model = AutoARIMA(season_length=SEASONAL_PERIOD)\n    best_model.fit(series_full)\n    final_forecast_ts = best_model.predict(FORECAST_HORIZON)\n    model_label = \"AutoARIMA SARIMA m=12 (Full Data)\"\n\nelif BEST_MODEL_TYPE == \"sarima_manual\":\n    # Update (p,d,q)(P,D,Q) based on best manual candidate from Section 16\n    best_model = ARIMA(p=1, d=1, q=1, seasonal_order=(1, 1, 1, SEASONAL_PERIOD))\n    best_model.fit(series_full)\n    final_forecast_ts = best_model.predict(FORECAST_HORIZON)\n    model_label = \"SARIMA(1,1,1)(1,1,1)[12] (Full Data)\"\n\n# Reassign correct future timestamps\nfinal_fc_vals = final_forecast_ts.pd_series().values\nfinal_fc_ts   = TimeSeries.from_times_and_values(\n    pd.DatetimeIndex(future_index), final_fc_vals\n)\n\n# \u2500\u2500 Log final forecast to MLflow \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\ntarget_exp = EXP_SMOOTHING if \"hw\" in BEST_MODEL_TYPE else EXP_ARIMA\nmlflow.set_experiment(target_exp)\n\nwith mlflow.start_run(run_name=f\"FINAL_FORECAST_{BEST_MODEL_TYPE.upper()}\"):\n    mlflow.set_tag(\"model_family\", BEST_MODEL_TYPE)\n    mlflow.set_tag(\"stage\",        \"production_forecast\")\n    mlflow.set_tag(\"trained_on\",   \"full_data_2019_2026\")\n    mlflow.log_param(\"forecast_horizon\", FORECAST_HORIZON)\n    mlflow.log_param(\"forecast_start\",   str(future_index[0].date()))\n    mlflow.log_param(\"forecast_end\",     str(future_index[-1].date()))\n    for i, (dt, val) in enumerate(zip(future_index, final_fc_vals), 1):\n        mlflow.log_metric(f\"forecast_month_{i}\", round(float(val), 2))\n\n    # Plot: last 24 months of history + 3-month forecast\n    hist_pd = series_full.pd_series().iloc[-24:]\n    fig, ax = plt.subplots(figsize=(13, 5))\n    ax.plot(hist_pd.index, hist_pd,\n            label=\"Historical (last 24 months)\", color=\"steelblue\", linewidth=1.5)\n    ax.plot(future_index, final_fc_vals,\n            label=\"3-Month Forecast\", color=\"tomato\", linewidth=2,\n            marker=\"o\", markersize=7)\n    ax.axvline(series_full.end_time(), linestyle=\"--\", color=\"gray\", linewidth=0.8)\n    ax.set_title(f\"3-Month Ahead Forecast \u2014 {model_label}\")\n    ax.set_ylabel(\"KWh\")\n    ax.yaxis.set_major_formatter(mticker.FuncFormatter(lambda x, _: f\"{x/1e6:.0f}M\"))\n    ax.legend()\n    ax.grid(alpha=0.3)\n    plt.tight_layout()\n    plt.savefig(\"13_final_forecast.png\", bbox_inches=\"tight\")\n    plt.show()\n    mlflow.log_artifact(\"13_final_forecast.png\")\n\nprint(\"\\n===== FINAL 3-MONTH FORECAST (Feb\u2013Apr 2026) =====\")\nfor dt, val in zip(future_index, final_fc_vals):\n    print(f\"  {dt.strftime('%Y-%m')}: {float(val):>20,.0f} KWh\")\n"
  },
  {
   "cell_type": "markdown",
   "id": "59560126",
   "metadata": {},
   "source": "## 19. View Results in MLflow UI\nLaunch the MLflow tracking UI from your terminal:\n```bash\nmlflow ui --port 5000\n```\nThen open: **http://localhost:5000**\n\nNavigate to:\n- `exponential_smoothing` experiment \u2192 compare SES, Holt, Holt-Winters variants by MAPE\n- `arima_sarima` experiment \u2192 compare ARIMA / SARIMA candidates by MAPE, AIC, BIC, Ljung-Box p\n\n**Artifacts logged per run**: forecast plot, residual ACF plot, pickled model file.\n"
  }
 ]
}